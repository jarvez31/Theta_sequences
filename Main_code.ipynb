{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarvez31/Theta_sequences/blob/main/Main_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import librabries"
      ],
      "metadata": {
        "id": "pXDw2AsyafOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fol = \"/Theta_sequence/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTE4n3Gx7Fnh",
        "outputId": "391a7d1d-173b-4fe7-a92a-b0506638ccc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/994.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m993.3/994.0 KB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFaB2tOOjiWL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import skfuzzy as fuzz\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import progressbar\n",
        "import pickle, random, tqdm, time\n",
        "from time import sleep\n",
        "from shapely.geometry import LineString, LinearRing, box, Point, Polygon\n",
        "\n",
        "#%%\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K  \n",
        "import numpy as np\n",
        "import math as mt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D, AveragePooling1D, UpSampling1D\n",
        "import pickle\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from numpy import linalg as LA\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from numpy import matlib\n",
        "import scipy.io\n",
        "from scipy import signal\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import random\n",
        "from keras import regularizers\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Parameters"
      ],
      "metadata": {
        "id": "0qHJl73yHlWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Folder for storage and trajectory name\n",
        "Train_enc = True #@param {type:\"boolean\"}\n",
        "Train_osc = False #@param {type:\"boolean\"}\n",
        "traj1 = \"traj_1.pk1\" #@param {type:\"string\"}\n",
        "# test_p =  7#@param {type:\"number\"}\n",
        "# img_fol = \"traj_four_objs_diffW\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Standard deviation for population code for x,y\n",
        "stdev =  0.1 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "#@markdown ### Model Params\n",
        "pi_use = \"no_osc\" #@param [\"osc\", \"no_osc\"]\n",
        "act_func = \"relu\" #@param {type:\"string\"}\n",
        "learn_rate = 0.0001 #@param {type:\"number\"}\n",
        "mean_freq = 42 #@param {type:\"number\"}\n",
        "dt = 0.002 #@param {type:\"number\"}\n",
        "beta =  6#@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xy_P3JuMHkX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PI and HD"
      ],
      "metadata": {
        "id": "w-ZI_rRNjyyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### LOAD TRAJECTORY ######\n",
        "traj_name = fol + traj1\n",
        "with open(traj_name, 'rb') as weight:\n",
        "    dd = pickle.load(weight)\n",
        "    weight.close()\n",
        "locals().update(dd)\n",
        "\n",
        "x=np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "vel = np.asarray(vel)\n",
        "theta = np.asarray(theta)\n",
        "cyclen = np.asarray(cyclen)"
      ],
      "metadata": {
        "id": "7v2FhABS8Z8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibEVz3hvnD2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4e7f79-b4d8-4468-94ad-bc39cce7885d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: \n",
            "(100, 307775)\n"
          ]
        }
      ],
      "source": [
        "#%% -----------------------------------Path Integraion------------------------------------##################\n",
        "n = 100\n",
        "bf = []\n",
        "gamma = []\n",
        "for k in range(n):\n",
        "    bf.append(2*mt.pi*np.random.normal(mean_freq,stdev)) # base frequency the requnecy is being multiplied with 2pi to conver into angles\n",
        "    if k < n/2: # couldn't completely understand this if condition, is it encoding direction?\n",
        "        gamma.append(1)\n",
        "    else:\n",
        "        gamma.append(-1)\n",
        "bf = np.reshape(np.asarray(bf), (n,1))\n",
        "gamma = np.reshape(np.asarray(gamma), (n,1))\n",
        "\n",
        "for ii in range(1,len(cyclen)): # Taking from the list of length of velocities\n",
        "    end = cyclen[ii]\n",
        "    start = cyclen[ii-1]\n",
        "    leng = end-start # Duration of a particular velocity vector\n",
        "\n",
        "    # t = np.linspace(0, dt*leng, num=leng, endpoint=False).reshape((1,leng)) # time corresponding to that length\n",
        "    # wt = np.matmul(bf,t) # Beta frequency multiplied by time gives number of cycles\n",
        "    x_temp = x[start:end].reshape((1,leng)) # Gives the position vector\n",
        "    a = np.matmul(gamma, x_temp) # Direction coded position? Moving away or towards the place field\n",
        "\n",
        "    a1 = float(beta)*a   # beta looks like parameter coding for theta precision which we will have to tune\n",
        "    if ii == 1:\n",
        "        Xarr_l = a1\n",
        "    else:\n",
        "        Xarr_l = np.column_stack((Xarr_l, a1))\n",
        "\n",
        "Xarr = Xarr_l\n",
        "pi_beta = np.cos(Xarr) # Converting into theta oscilations\n",
        "print(\"Shape is: \")\n",
        "print(pi_beta.shape)\n",
        "pi_thresh = pi_beta # Theta oscilations sets the thresholds for the place field cells, the crux of theta sequences\n",
        "mn = (np.matlib.repmat(np.mean(pi_thresh, axis=1), cyclen[ii], 1)) # For repeating the given array\n",
        "pi_nor = pi_thresh.T - mn # mean centered(normalized) threshold values\n",
        "PI1d = pi_nor\n",
        "d = {\"gamma\":gamma, \"PI1d\":PI1d, \"bf\":bf} #, 'obj': small_box}\n",
        "with open(fol + '/HD_PI.pk1', 'wb') as f:\n",
        "    pickle.dump(d, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoders"
      ],
      "metadata": {
        "id": "YqRrkUrNj2So"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2dDDU2xxJs9"
      },
      "outputs": [],
      "source": [
        "# Train=True\n",
        "if Train_enc:\n",
        "    input_data = Input(shape=100,)\n",
        "\n",
        "    encoder = Dense(30, input_dim = (100,), activation='relu')(input_data)\n",
        "    decoder = Dense(100, input_dim = (30,), activation='relu')(encoder)\n",
        "\n",
        "    autoencoder = Model(input_data, decoder)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    autoencoder.compile(optimizer=opt, loss='mse')\n",
        "    autoencoder.summary()\n",
        "    plot_model(autoencoder, to_file='phase.png', show_shapes=True, show_layer_names=True)\n",
        "    encoderModel = Model(input_data, encoder)\n",
        "    encoderModel.compile(optimizer=opt, loss='mse')\n",
        "    data = np.array(PI1d[:cyclen[-6],:])\n",
        "    x_train, x_test, = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    autoencoder.fit(x_train, \n",
        "                    x_train,\n",
        "                    epochs= 40,\n",
        "                    # steps_per_epoch= 100,\n",
        "                    batch_size= 512,\n",
        "                    validation_data= (x_test,x_test),\n",
        "                    validation_steps= 10,\n",
        "                    shuffle= False)\n",
        "    encoderModel.save(fol + \"encoder_beta9_S1.h5\")\n",
        "    autoencoder.save(fol + \"autoencoder_beta9_S1.h5\")\n",
        "\n",
        "#%% \n",
        "# ----------------------------------Encoder and Decoder (Model-2)-------------------------------##################\n",
        "if Train_enc:\n",
        "    input_data = Input(shape=30,)\n",
        "\n",
        "    encoder = Dense(30, input_dim = (30,), activation='relu')(input_data)\n",
        "    decoder = Dense(30, input_dim = (30,), activation='relu')(encoder)\n",
        "    autoencoder = Model(input_data, decoder)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    autoencoder.compile(optimizer=opt, loss='mse')\n",
        "    autoencoder.summary()\n",
        "    plot_model(autoencoder, to_file='phase.png', show_shapes=True, show_layer_names=True)\n",
        "    encoderModel = Model(input_data, encoder)\n",
        "    encoder_model1 = tf.keras.models.load_model(fol + \"encoder_beta9_S1.h5\")\n",
        "    data1 = encoder_model1.predict(PI1d[:cyclen[-6],:]) \n",
        "    x_train1, x_test1, = train_test_split(data1, test_size=0.1, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    autoencoder.fit(x_train1, \n",
        "                    x_train1,\n",
        "                    epochs= 40,\n",
        "                    # steps_per_epoch= 100,\n",
        "                    batch_size= 512,\n",
        "                    validation_data= (x_test1,x_test1),\n",
        "                    validation_steps= 10,\n",
        "                    shuffle= False)\n",
        "    encoderModel.save(fol + \"encoder_beta9_S2.h5\")\n",
        "    autoencoder.save(fol + \"autoencoder_beta9_S2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outputs"
      ],
      "metadata": {
        "id": "Ze3FQRP1j4zF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k37TH0f_nSO"
      },
      "outputs": [],
      "source": [
        "#%%-----------------------Loading and plotting the results-------------------------------\n",
        "#model 1\n",
        "encoder_model = tf.keras.models.load_model(fol + \"encoder_beta9_S1.h5\")\n",
        "encoded = encoder_model.predict(PI1d)\n",
        "\n",
        "#model 2\n",
        "encoder2_model = tf.keras.models.load_model(fol + \"encoder_beta9_S2.h5\")\n",
        "encoded2 = encoder2_model.predict(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "  from matplotlib.pyplot import close\n",
        "  outs = [encoded2[cyclen[26]:cyclen[27]]] # output from one back and forth cycle\n",
        "  lim = [0.8]\n",
        "  outs_n = [\"MEC\", \"LEC\"]\n",
        "  pos_out = pos\n",
        "\n",
        "  for k in range(len(outs)):\n",
        "      resp_neurons = np.transpose(outs[k])\n",
        "      avg = np.mean(abs(resp_neurons))\n",
        "      std_dev = np.std(resp_neurons)\n",
        "      print(avg)\n",
        "      print(std_dev)\n",
        "      m = np.amax(resp_neurons)\n",
        "      print(m)\n",
        "      num = 0\n",
        "      for j in range(int(np.divide(len(resp_neurons),30))):\n",
        "          onm = outs_n[k]\n",
        "          for i in range(30):\n",
        "              plt.subplot(5,6,i+1)\n",
        "              thresh = np.amax(resp_neurons[i+num]) * lim[k]\n",
        "              firr = np.nonzero(resp_neurons[i+num]>thresh)\n",
        "              firposgrid = pos_out[firr[0], :]\n",
        "              plt.scatter(firposgrid[:,0], firposgrid[:,1], s = 1, color = 'red', marker='o', zorder = 5)\n",
        "              plt.plot(env[0], env[1])\n",
        "              plt.suptitle('output mesh without obj '+str(num)+ ' to '+str(num+30)+' neurons from '+ onm +' layer, threshold=' +str(lim)+\" act_func=\" + \"relu\", fontsize = 20, va = 'bottom', ha = 'center')\n",
        "\n",
        "          figure = plt.gcf() # get current figure\n",
        "          figure.set_size_inches(16, 10)\n",
        "          plt.show()\n",
        "          close()\n",
        "          num = num + 30"
      ],
      "metadata": {
        "id": "VHmNDGc7OTqV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}